{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network model for restaurant recomndation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vrinda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9700/9700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.0879\n",
      "Epoch 2/20\n",
      "\u001b[1m9700/9700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.0835\n",
      "Epoch 3/20\n",
      "\u001b[1m9700/9700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0835\n",
      "Epoch 4/20\n",
      "\u001b[1m9700/9700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0835\n",
      "Epoch 5/20\n",
      "\u001b[1m9700/9700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 0.0834\n",
      "Epoch 6/20\n",
      "\u001b[1m4246/9700\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0835"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load user data from CSV\n",
    "user_df = pd.read_csv('user.csv')\n",
    "\n",
    "# Load restaurant data from CSV\n",
    "restaurant_df = pd.read_csv('restaurant.csv')\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return scaled_data\n",
    "\n",
    "# Define neural network architectures\n",
    "def create_user_nn(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(258, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(embedding_size)  \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_restaurant_nn(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(258, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(embedding_size)  \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train neural networks\n",
    "def train_user_nn(user_data):\n",
    "    scaled_user_data = preprocess_data(user_data)\n",
    "    input_shape = scaled_user_data.shape[1:]\n",
    "    \n",
    "    model = create_user_nn(input_shape)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(scaled_user_data, user_labels, epochs=num_epochs, batch_size=batch_size)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_restaurant_nn(restaurant_data):\n",
    "    scaled_restaurant_data = preprocess_data(restaurant_data)\n",
    "    input_shape = scaled_restaurant_data.shape[1:]\n",
    "    \n",
    "    model = create_restaurant_nn(input_shape)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(scaled_restaurant_data, restaurant_labels, epochs=num_epochs, batch_size=batch_size)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Compute embeddings\n",
    "def compute_embeddings(model, data):\n",
    "    scaled_data = preprocess_data(data)\n",
    "    embeddings = model.predict(scaled_data)\n",
    "    return embeddings\n",
    "\n",
    "# Recommendation prediction\n",
    "def predict_recommendations(user_embedding, restaurant_embeddings):\n",
    "    scores = np.dot(user_embedding, restaurant_embeddings.T)\n",
    "    recommendations = np.argsort(scores)[::-1]  \n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "# Example usage with optimizations\n",
    "user_data = user_df[['stars_count']].values\n",
    "restaurant_data = restaurant_df.drop(columns=['business_id', 'name', 'stars']).values\n",
    "\n",
    "embedding_size = 32  # Adjust the embedding size to match the label size\n",
    "user_labels = np.random.rand(user_data.shape[0], embedding_size)  # Random labels for demonstration\n",
    "restaurant_labels = np.random.rand(restaurant_data.shape[0], embedding_size)\n",
    "\n",
    "num_epochs = 20  # Increase number of epochs\n",
    "batch_size = 28  # Increase batch size\n",
    "\n",
    "# Define and compile neural network models\n",
    "user_nn = create_user_nn(user_data.shape[1:])\n",
    "user_nn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "restaurant_nn = create_restaurant_nn(restaurant_data.shape[1:])\n",
    "restaurant_nn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "\n",
    "# Train neural network models\n",
    "user_nn.fit(preprocess_data(user_data), user_labels, epochs=num_epochs, batch_size=batch_size, verbose=1)\n",
    "restaurant_nn.fit(preprocess_data(restaurant_data), restaurant_labels, epochs=num_epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Compute embeddings\n",
    "user_embeddings = compute_embeddings(user_nn, user_data)\n",
    "restaurant_embeddings = compute_embeddings(restaurant_nn, restaurant_data)\n",
    "\n",
    "# Recommendation prediction using dot product\n",
    "\n",
    "# Recommendation prediction using sum of squared distances with business details\n",
    "def predict_recommendations_with_details(user_id, user_embedding, restaurant_embeddings, restaurant_df):\n",
    "    scores = np.dot(user_embedding, restaurant_embeddings.T)\n",
    "    recommendations_indices = np.argsort(scores)[::-1]\n",
    "    recommendations = []\n",
    "\n",
    "    for index in recommendations_indices:\n",
    "        business_id = restaurant_df.iloc[index]['business_id']\n",
    "        business_name = restaurant_df.iloc[index]['name']\n",
    "        recommendations.append({'user_id': user_id, 'business_id': business_id, 'business_name': business_name})\n",
    "        \n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "user_id = '-0vutwuE36iYMqM2wHaStQ'  # Example user ID\n",
    "user_data_for_prediction = user_df[user_df['user_id'] == user_id][['stars_count']].values\n",
    "user_embedding = compute_embeddings(user_nn, user_data_for_prediction).squeeze()\n",
    "\n",
    "recommendations_with_details = predict_recommendations_with_details(user_id, user_embedding, restaurant_embeddings, restaurant_df)\n",
    "print(\"Top recommended restaurants with details:\")\n",
    "for recommendation in recommendations_with_details[:10]:\n",
    "    print(recommendation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosSine model for restaurant recommendation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "user_data = pd.read_csv('user.csv')\n",
    "restaurant_data = pd.read_csv('restaurant.csv')\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "# Drop unnecessary columns\n",
    "user_preferences = user_data.drop(columns=['user_id', 'stars_count'])\n",
    "\n",
    "# Scale the user preferences using Min-Max Scaling\n",
    "minmax_scaler = MinMaxScaler()\n",
    "user_preferences_scaled = minmax_scaler.fit_transform(user_preferences)\n",
    "\n",
    "# Drop non-numeric columns from restaurant data\n",
    "restaurant_features = restaurant_data.drop(columns=['business_id', 'name', 'stars'])\n",
    "\n",
    "# Scale the restaurant features using Standard Scaling\n",
    "standard_scaler = StandardScaler()\n",
    "restaurant_features_scaled = standard_scaler.fit_transform(restaurant_features)\n",
    "\n",
    "# Step 3: Calculate cosine similarity between users and restaurants\n",
    "# Calculate cosine similarity between users and restaurants\n",
    "user_restaurant_similarity = cosine_similarity(user_preferences_scaled, restaurant_features_scaled)\n",
    "\n",
    "# Step 4: Generate recommendations for a given user\n",
    "# Step 4: Generate recommendations for a given user\n",
    "def recommend_highest_rated_restaurants(user_id, n=10):\n",
    "    # Find the index of the user in the user_data\n",
    "    user_index = user_data[user_data['user_id'] == user_id].index[0]\n",
    "    # Get the similarity scores for the given user\n",
    "    user_scores = user_restaurant_similarity[user_index]\n",
    "    # Find the indices of the top n restaurants with the highest similarity scores\n",
    "    top_indices = user_scores.argsort()[-n:][::-1]\n",
    "    # Get the corresponding business IDs, names, and their similarity scores\n",
    "    recommendations = [(restaurant_data.iloc[i]['business_id'], restaurant_data.iloc[i]['name'], user_scores[i]) for i in top_indices]\n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "user_id = '--Dz7-yZ5vMuDdlHxfBWVw'  # Provide the user_id for whom you want to make recommendations\n",
    "recommendations = recommend_highest_rated_restaurants(user_id)\n",
    "\n",
    "print(\"Top 10 Recommended Businesses with Cosine Similarity Values:\")\n",
    "for i, (business_id, business_name, similarity_score) in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. Business ID: {business_id}, Business Name: {business_name}, Similarity Score: {similarity_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
